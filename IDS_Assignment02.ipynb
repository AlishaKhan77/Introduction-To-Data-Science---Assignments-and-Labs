{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f5fbe6-62d1-4b91-900d-9119c26f7b81",
   "metadata": {},
   "source": [
    "# Part1:  User Data Processing with Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d531d81-fce6-4cb6-8a20-1071ffda05bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Users: [(40, 'Isaac Evans', 56, 'Pakistan'), (41, 'Aaliyah Sanders', 55, 'USA'), (50, 'Hannah Long', 32, 'Pakistan')]\n",
      "Names: ['Isaac Evans', 'Aaliyah Sanders', 'Hannah Long']\n",
      "\n",
      "Top 10 Oldest Users: [(40, 'Isaac Evans', 56, 'Pakistan'), (41, 'Aaliyah Sanders', 55, 'USA'), (38, 'Luke Campbell', 47, 'Australia'), (48, 'Luna Bailey', 46, 'Australia'), (8, 'James Anderson', 45, 'Australia'), (28, 'Daniel Evans', 44, 'Australia'), (47, 'Levi Powell', 43, 'Spain'), (24, 'Henry Wright', 42, 'Germany'), (14, 'Noah Harris', 41, 'Germany'), (34, 'David Perez', 41, 'Germany')]\n",
      "Duplicate Names: ['Alisha Khan']\n"
     ]
    }
   ],
   "source": [
    "data_tuple = [\n",
    "    (1, 'Alisha Khan', 20, 'USA'),\n",
    "    (2, 'David Smith', 34, 'Canada'),\n",
    "    (3, 'Sara Ali', 22, 'UK'),\n",
    "    (4, 'John Doe', 29, 'Germany'),\n",
    "    (5, 'Emma Williams', 40, 'France'),\n",
    "    (6, 'Michael Brown', 31, 'Italy'),\n",
    "    (7, 'Sophia Johnson', 27, 'Spain'),\n",
    "    (8, 'James Anderson', 45, 'Australia'),\n",
    "    (9, 'Ava Wilson', 19, 'India'),\n",
    "    (10, 'Ethan Lee', 38, 'Brazil'),\n",
    "    (11, 'Mia Thompson', 23, 'USA'),\n",
    "    (12, 'Alisha Khan', 35, 'Canada'),\n",
    "    (13, 'Olivia Martin', 28, 'UK'),\n",
    "    (14, 'Noah Harris', 41, 'Germany'),\n",
    "    (15, 'Isabella Clark', 30, 'France'),\n",
    "    (16, 'Lucas Robinson', 26, 'Italy'),\n",
    "    (17, 'Amelia Lewis', 32, 'Spain'),\n",
    "    (18, 'Benjamin Scott', 37, 'Australia'),\n",
    "    (19, 'Ella Rodriguez', 21, 'India'),\n",
    "    (20, 'Mason White', 39, 'Brazil'),\n",
    "    (21, 'Chloe Hall', 24, 'USA'),\n",
    "    (22, 'Alexander Young', 36, 'Canada'),\n",
    "    (23, 'Charlotte King', 33, 'UK'),\n",
    "    (24, 'Henry Wright', 42, 'Germany'),\n",
    "    (25, 'Aiden Baker', 29, 'France'),\n",
    "    (26, 'Sebastian Taylor', 30, 'Italy'),\n",
    "    (27, 'Aria Moore', 22, 'Spain'),\n",
    "    (28, 'Daniel Evans', 44, 'Australia'),\n",
    "    (29, 'Grace Turner', 20, 'India'),\n",
    "    (30, 'Samuel Gonzalez', 36, 'Brazil'),\n",
    "    (31, 'Victoria Adams', 27, 'USA'),\n",
    "    (32, 'Matthew Carter', 34, 'Canada'),\n",
    "    (33, 'Scarlett Roberts', 25, 'UK'),\n",
    "    (34, 'David Perez', 41, 'Germany'),\n",
    "    (35, 'Zoe Stewart', 39, 'France'),\n",
    "    (36, 'Logan Ramirez', 30, 'Italy'),\n",
    "    (37, 'Lily Peterson', 23, 'Spain'),\n",
    "    (38, 'Luke Campbell', 47, 'Australia'),\n",
    "    (39, 'Natalie Parker', 18, 'India'),\n",
    "    (40, 'Isaac Evans', 56, 'Pakistan'),\n",
    "    (41, 'Aaliyah Sanders', 55, 'USA'),\n",
    "    (42, 'Jayden Flores', 29, 'Canada'),\n",
    "    (43, 'Eleanor Diaz', 33, 'UK'),\n",
    "    (44, 'Gabriel Morales', 38, 'Germany'),\n",
    "    (45, 'Emily Hernandez', 28, 'France'),\n",
    "    (46, 'Jackson Brooks', 31, 'Italy'),\n",
    "    (47, 'Levi Powell', 43, 'Spain'),\n",
    "    (48, 'Luna Bailey', 46, 'Australia'),\n",
    "    (49, 'Nolan Jenkins', 30, 'Brazil'),\n",
    "    (50, 'Hannah Long', 32, 'Pakistan')\n",
    "]\n",
    "\n",
    "def func1(d):\n",
    "    filtered_users = []\n",
    "    names = []\n",
    "    for i in range(len(d)):\n",
    "        if d[i][2] >= 30 and (d[i][3] == 'USA' or d[i][3] == 'Pakistan'):\n",
    "            filtered_users.append(d[i])\n",
    "            names.append(d[i][1])\n",
    "    print(\"Filtered Users:\", filtered_users)\n",
    "    print(\"Names:\", names)\n",
    "\n",
    "func1(data_tuple)\n",
    "print()\n",
    "\n",
    "def func2(d):\n",
    "    sorted_data = sorted(d, key=lambda x: x[2], reverse=True)\n",
    "    oldest_users = sorted_data[:10]\n",
    "    print(\"Top 10 Oldest Users:\", oldest_users)\n",
    "    \n",
    "    seen_names = set()\n",
    "    duplicate_names = set()\n",
    "    for user in d:\n",
    "        if user[1] in seen_names:\n",
    "            duplicate_names.add(user[1])\n",
    "        else:\n",
    "            seen_names.add(user[1])\n",
    "\n",
    "    if duplicate_names:\n",
    "        print(\"Duplicate Names:\", list(duplicate_names))\n",
    "    else:\n",
    "        print(\"No Duplicate Names\")\n",
    "\n",
    "func2(data_tuple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14bbb57-9a2e-4922-8673-705eed77ab4e",
   "metadata": {},
   "source": [
    "# Part 2: Immutable Data Management with Tuples\n",
    "Inconsistent tuple sizes can lead to indexing errors and logical inconsistencies when accessing or processing data. This requires additional validation steps and can result in incorrect or incomplete results.There might be differrent position of ids and users in different tuples that will lead to inconsistencies in the esultant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2d9a3c-fcf5-426d-974d-4fb1ed599ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 10\n",
      "\n",
      "Transaction with the highest amount: (40, 404, 43100.0, '2023-04-09')\n",
      "\n",
      "Transaction IDs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "User IDs: [301, 202, 404, 505, 606, 303, 707, 808, 909, 101]\n"
     ]
    }
   ],
   "source": [
    "transaction_records = [\n",
    "    (1, 301, 1050.0, '2023-03-01'),\n",
    "    (2, 202, 2100.0, '2023-03-02'),\n",
    "    (3, 301, 3200.0, '2023-03-03'),\n",
    "    (4, 404, 4300.0, '2023-03-04'),\n",
    "    (5, 505, 5500.0, '2023-03-05'),\n",
    "    (6, 202, 6600.0, '2023-03-06'),\n",
    "    (7, 606, 7700.0, '2023-03-07'),\n",
    "    (8, 303, 8800.0, '2023-03-08'),\n",
    "    (9, 505, 9900.0, '2023-03-09'),\n",
    "    (10, 707, 10100.0, '2023-03-10'),\n",
    "    (11, 404, 11200.0, '2023-03-11'),\n",
    "    (12, 202, 12300.0, '2023-03-12'),\n",
    "    (13, 808, 13400.0, '2023-03-13'),\n",
    "    (14, 606, 14500.0, '2023-03-14'),\n",
    "    (15, 202, 15600.0, '2023-03-15'),\n",
    "    (16, 909, 16700.0, '2023-03-16'),\n",
    "    (17, 101, 17800.0, '2023-03-17'),\n",
    "    (18, 404, 18900.0, '2023-03-18'),\n",
    "    (19, 303, 20000.0, '2023-03-19'),\n",
    "    (20, 606, 21100.0, '2023-03-20'),\n",
    "    (21, 808, 22200.0, '2023-03-21'),\n",
    "    (22, 101, 23300.0, '2023-03-22'),\n",
    "    (23, 505, 24400.0, '2023-03-23'),\n",
    "    (24, 909, 25500.0, '2023-03-24'),\n",
    "    (25, 101, 26600.0, '2023-03-25'),\n",
    "    (26, 202, 27700.0, '2023-03-26'),\n",
    "    (27, 808, 28800.0, '2023-03-27'),\n",
    "    (28, 606, 29900.0, '2023-03-28'),\n",
    "    (29, 404, 31000.0, '2023-03-29'),\n",
    "    (30, 101, 32100.0, '2023-03-30'),\n",
    "    (31, 707, 33200.0, '2023-03-31'),\n",
    "    (32, 808, 34300.0, '2023-04-01'),\n",
    "    (33, 909, 35400.0, '2023-04-02'),\n",
    "    (34, 101, 36500.0, '2023-04-03'),\n",
    "    (35, 505, 37600.0, '2023-04-04'),\n",
    "    (36, 202, 38700.0, '2023-04-05'),\n",
    "    (37, 606, 39800.0, '2023-04-06'),\n",
    "    (38, 909, 40900.0, '2023-04-07'),\n",
    "    (39, 101, 42000.0, '2023-04-08'),\n",
    "    (40, 404, 43100.0, '2023-04-09')\n",
    "]\n",
    "\n",
    "def unique_users(records):\n",
    "    unique_users_list = []\n",
    "    for transaction in records:\n",
    "        if transaction[1] not in unique_users_list:\n",
    "            unique_users_list.append(transaction[1])\n",
    "\n",
    "    print(f\"Number of unique users: {len(unique_users_list)}\")\n",
    "\n",
    "unique_users(transaction_records)\n",
    "print()\n",
    "\n",
    "def highest_transaction(records):\n",
    "    sorted_transactions = sorted(records, key=lambda x: x[2], reverse=True)\n",
    "    print(f\"Transaction with the highest amount: {sorted_transactions[0]}\")\n",
    "\n",
    "highest_transaction(transaction_records)\n",
    "print()\n",
    "\n",
    "def separate_ids_and_users(records):\n",
    "    transaction_ids = []\n",
    "    user_ids = []\n",
    "    for record in records:\n",
    "        if record[0] not in transaction_ids:\n",
    "            transaction_ids.append(record[0])\n",
    "        if record[1] not in user_ids:\n",
    "            user_ids.append(record[1])\n",
    "\n",
    "    print(f\"Transaction IDs: {transaction_ids}\")\n",
    "    print(f\"User IDs: {user_ids}\")\n",
    "\n",
    "separate_ids_and_users(transaction_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef84f9-c284-4742-adbb-91dea22ca071",
   "metadata": {},
   "source": [
    "# Part 3: Unique Data Handling with Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817ab45f-75b9-4aa2-8aec-835a639910ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{24, 25, 26}\n",
      "{21, 22, 23, 27, 28, 29, 30}\n",
      "\n",
      "{21, 22, 23, 24, 25, 26, 44, 45, 46, 47}\n",
      "{25, 26, 27}\n"
     ]
    }
   ],
   "source": [
    "group_x = {21, 22, 23, 24, 25, 26}\n",
    "group_y = {24, 25, 26, 27, 28, 29, 30}\n",
    "group_z = {31, 32, 22, 25, 33}\n",
    "\n",
    "def process_sets(x, y, z):\n",
    "    print(x & y)\n",
    "    print((x | y) - (x & y))\n",
    "\n",
    "process_sets(group_x, group_y, group_z)\n",
    "print()\n",
    "\n",
    "def modify_sets(x, y, z):\n",
    "    group_x.add(44)\n",
    "    group_x.update([45, 46, 47])\n",
    "    print(group_x)\n",
    "  \n",
    "    group_y.remove(24)\n",
    "    group_y.difference_update([28, 29, 30])\n",
    "    group_y.discard(28)  \n",
    "    print(group_y)\n",
    "\n",
    "modify_sets(group_x, group_y, group_z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a96a2-4c9f-48ce-819c-a6f78dec14fb",
   "metadata": {},
   "source": [
    "# Part 4: Data Aggregation with Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c122846-4de9-4381-b5ef-7b2ce15ccc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{202: 5, 404: 4, 505: 5}\n",
      "\n",
      "{202: {'rating': 5, 'comments': 'Fantastic! Would highly recommend.'}, 505: {'rating': 5, 'comments': 'Fantastic! Would highly recommend.'}, 404: {'rating': 4, 'comments': 'Decent quality, but could be cheaper.'}, 101: {'rating': 3, 'comments': 'Decent quality, but could be cheaper.'}, 606: {'rating': 2, 'comments': 'Not up to the mark.'}}\n",
      "\n",
      "101: Rating = 4, Comments = Decent quality, but could be cheaper. Reasonable price for quality.\n",
      "202: Rating = 5, Comments = Fantastic! Would highly recommend. Would still recommend, even after more use.\n",
      "303: Rating = 2, Comments = Very disappointing. Did not improve over time.\n",
      "404: Rating = 4, Comments = Decent quality, but could be cheaper.\n",
      "505: Rating = 5, Comments = Fantastic! Would highly recommend.\n",
      "606: Rating = 2, Comments = Not up to the mark.\n",
      "707: Rating = 5, Comments = Impressive product with high value.\n",
      "808: Rating = 3, Comments = Quality could be improved.\n",
      "909: Rating = 5, Comments = Exceeded my expectations!\n"
     ]
    }
   ],
   "source": [
    "feedback_data1 = {\n",
    "    101: {'rating': 3, 'comments': \"Decent quality, but could be cheaper.\"},\n",
    "    202: {'rating': 5, 'comments': \"Fantastic! Would highly recommend.\"},\n",
    "    303: {'rating': 1, 'comments': \"Very disappointing.\"},\n",
    "    404: {'rating': 4, 'comments': \"Decent quality, but could be cheaper.\"},\n",
    "    505: {'rating': 5, 'comments': \"Fantastic! Would highly recommend.\"},\n",
    "    606: {'rating': 2, 'comments': \"Not up to the mark.\"}\n",
    "}\n",
    "\n",
    "feedback_data2 = {\n",
    "    101: {'rating': 4, 'comments': \"Reasonable price for quality.\"},\n",
    "    202: {'rating': 4, 'comments': \"Would still recommend, even after more use.\"},\n",
    "    303: {'rating': 2, 'comments': \"Did not improve over time.\"},\n",
    "    707: {'rating': 5, 'comments': \"Impressive product with high value.\"},\n",
    "    808: {'rating': 3, 'comments': \"Quality could be improved.\"},\n",
    "    909: {'rating': 5, 'comments': \"Exceeded my expectations!\"}\n",
    "}\n",
    "\n",
    "def filter_feedback(data):\n",
    "    high_ratings = []\n",
    "    for user_id, feedback in data.items():\n",
    "        if feedback['rating'] >= 4:\n",
    "            high_ratings.append((user_id, feedback['rating']))\n",
    "    high_ratings = dict(high_ratings)\n",
    "    print(high_ratings)\n",
    "\n",
    "filter_feedback(feedback_data1)\n",
    "print()\n",
    "\n",
    "\n",
    "def sort_feedback(data):\n",
    "    sorted_data = sorted(data.items(), key=lambda x: x[1]['rating'], reverse=True)\n",
    "    top_ratings = dict(sorted_data[:5])  # Fetch top 5 ratings\n",
    "    print(top_ratings)\n",
    "\n",
    "sort_feedback(feedback_data1)\n",
    "print()\n",
    "\n",
    "\n",
    "def merge_feedback(data1, data2):\n",
    "    all_feedback = [data1, data2]\n",
    "    merged_feedback = {}\n",
    "\n",
    "    for feedback in all_feedback:\n",
    "        for user, details in feedback.items():\n",
    "            if user in merged_feedback:\n",
    "                merged_feedback[user][\"rating\"] = max(merged_feedback[user][\"rating\"], details[\"rating\"])\n",
    "                merged_feedback[user][\"comments\"] += \" \" + details[\"comments\"]\n",
    "            else:\n",
    "                merged_feedback[user] = details.copy()\n",
    "\n",
    "    for user, details in merged_feedback.items():\n",
    "        print(f\"{user}: Rating = {details['rating']}, Comments = {details['comments']}\")\n",
    "\n",
    "merge_feedback(feedback_data1, feedback_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13754044-0a18-4d77-afd2-0f59bc4afeef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
